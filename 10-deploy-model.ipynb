{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model\n",
    "**Important**: Change the kernel to *PROJECT_NAME local*. You can do this from the *Kernel* menu under *Change kernel*. You cannot deploy the model using the *PROJECT_NAME docker* kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.api.schema.dataTypes import DataTypes\n",
    "from azureml.api.schema.sampleDefinition import SampleDefinition\n",
    "from azureml.api.realtime.services import generate_schema\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imp\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.logging.script_run_request.ScriptRunRequest at 0x179571c5ef0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.logging import get_azureml_logger\n",
    "run_logger = get_azureml_logger()\n",
    "run_logger.log('amlrealworld.timeseries.deploy-model','true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the name of the model to deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dtree\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test dataset and retain just one row. This record will be used to create and input schema for the web service. It will also allow us to simulate invoking the web service with features for one hour period and generating a demand forecast for this hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precip</th>\n",
       "      <th>temp</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>temp_lag1</th>\n",
       "      <th>temp_lag2</th>\n",
       "      <th>temp_lag3</th>\n",
       "      <th>temp_lag4</th>\n",
       "      <th>temp_lag5</th>\n",
       "      <th>temp_lag6</th>\n",
       "      <th>demand_lag1</th>\n",
       "      <th>demand_lag2</th>\n",
       "      <th>demand_lag3</th>\n",
       "      <th>demand_lag4</th>\n",
       "      <th>demand_lag5</th>\n",
       "      <th>demand_lag6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>74.63</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>75.1</td>\n",
       "      <td>75.72</td>\n",
       "      <td>76.72</td>\n",
       "      <td>75.85</td>\n",
       "      <td>77.36</td>\n",
       "      <td>80.92</td>\n",
       "      <td>6912.7</td>\n",
       "      <td>7332.625</td>\n",
       "      <td>7576.558</td>\n",
       "      <td>7603.008</td>\n",
       "      <td>7788.292</td>\n",
       "      <td>8102.142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precip   temp  hour     ...       demand_lag4  demand_lag5  demand_lag6\n",
       "0     0.0  74.63     0     ...          7603.008     7788.292     8102.142\n",
       "\n",
       "[1 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml_dir = os.environ['AZUREML_NATIVE_SHARE_DIRECTORY']\n",
    "test_df = pd.read_csv(os.path.join(aml_dir, 'nyc_demand_test.csv'), parse_dates=['timeStamp'])\n",
    "test_df = test_df.drop(['demand', 'timeStamp'], axis=1).copy().iloc[[0]]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from disk and transfer it to the working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"C:/Users/nelgoh/Desktop/Resources/Petronas/energy_demand_forecast/EnergyDemandForecast/models/\"\n",
    "with open(os.path.join(model_dir, model_name + '.pkl'), 'rb') as f:\n",
    "    mod = pickle.load(f)\n",
    "\n",
    "# with open('model_deploy.pkl', 'wb') as f:\n",
    "#     pickle.dump(mod, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check model object has loaded as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('regr_cv', RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3), error_score='raise',\n",
       "          estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "     ...it=True,\n",
       "          return_train_score=True, scoring='neg_mean_squared_error',\n",
       "          verbose=2))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply model to predict test record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6431.91218181818"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asscalar(mod.predict(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author a realtime web service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a score.py script which implements the scoring function to run inside the web service. Change model_name variable as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:/Users/nelgoh/Desktop/Resources/Petronas/energy_demand_forecast/EnergyDemandForecast/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:/Users/nelgoh/Desktop/Resources/Petronas/energy_demand_forecast/EnergyDemandForecast/score.py\n",
    "# The init and run functions will load and score the input using the saved model.\n",
    "# The score.py file will be included in the web service deployment package.\n",
    "def init():\n",
    "    from sklearn.externals import joblib\n",
    "    import pickle\n",
    "    import os\n",
    "    global model\n",
    "    \n",
    "    model_dir = \"./models/dtree.pkl\"\n",
    "    model = joblib.load(model_dir)\n",
    "#     model_dir = \"C:/Users/nelgoh/Desktop/Resources/Petronas/energy_demand_forecast/EnergyDemandForecast/models/\"\n",
    "#     with open(os.path.join(model_dir, model_name + '.pkl'), 'rb') as f:\n",
    "#         model = pickle.load(f)\n",
    "#     with open('model_deploy.pkl', 'rb') as f:\n",
    "#         model = pickle.load(f)\n",
    "    \n",
    "def run(input_df):\n",
    "    input_df = input_df[['precip', 'temp', 'hour', 'month', 'dayofweek',\n",
    "        'temp_lag1', 'temp_lag2', 'temp_lag3', 'temp_lag4', 'temp_lag5',\n",
    "        'temp_lag6', 'demand_lag1', 'demand_lag2', 'demand_lag3',\n",
    "        'demand_lag4', 'demand_lag5', 'demand_lag6']]\n",
    "    try:\n",
    "        if (input_df.shape != (1,17)):\n",
    "            return 'Bad imput: Expecting dataframe of shape (1,17)'\n",
    "        else:\n",
    "            pred = model.predict(input_df)\n",
    "            return int(pred)\n",
    "    except Exception as e:\n",
    "        return(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will be written to the current working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the *init* and *run* functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'score' from 'C:\\\\Users\\\\nelgoh\\\\AppData\\\\Local\\\\Temp\\\\4\\\\azureml_runs\\\\EnergyDemandForecast_1538106716523\\\\score.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import score\n",
    "imp.reload(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6431"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.init()\n",
    "score.run(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create web service schema\n",
    "The web service schema provides details on the required structure of the input data as well as the data types of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': {'input_df': {'internal': 'gANjYXp1cmVtbC5hcGkuc2NoZW1hLnBhbmRhc1V0aWwKUGFuZGFzU2NoZW1hCnEAKYFxAX1xAihYDAAAAGNvbHVtbl90eXBlc3EDXXEEKGNudW1weQpkdHlwZQpxBVgCAAAAZjhxBksASwGHcQdScQgoSwNYAQAAADxxCU5OTkr/////Sv////9LAHRxCmJoCGgFWAIAAABpOHELSwBLAYdxDFJxDShLA2gJTk5OSv////9K/////0sAdHEOYmgNaA1oCGgIaAhoCGgIaAhoCGgIaAhoCGgIaAhlWAUAAABzaGFwZXEPSwFLEYZxEFgMAAAAY29sdW1uX25hbWVzcRFdcRIoWAYAAABwcmVjaXBxE1gEAAAAdGVtcHEUWAQAAABob3VycRVYBQAAAG1vbnRocRZYCQAAAGRheW9md2Vla3EXWAkAAAB0ZW1wX2xhZzFxGFgJAAAAdGVtcF9sYWcycRlYCQAAAHRlbXBfbGFnM3EaWAkAAAB0ZW1wX2xhZzRxG1gJAAAAdGVtcF9sYWc1cRxYCQAAAHRlbXBfbGFnNnEdWAsAAABkZW1hbmRfbGFnMXEeWAsAAABkZW1hbmRfbGFnMnEfWAsAAABkZW1hbmRfbGFnM3EgWAsAAABkZW1hbmRfbGFnNHEhWAsAAABkZW1hbmRfbGFnNXEiWAsAAABkZW1hbmRfbGFnNnEjZVgKAAAAc2NoZW1hX21hcHEkfXElKGgeaAhoF2gNaCBoCGgTaAhoHGgIaBtoCGghaAhoFmgNaBhoCGgaaAhoH2gIaB1oCGgiaAhoGWgIaCNoCGgVaA1oFGgIdXViLg==',\n",
       "   'swagger': {'example': [{'dayofweek': 4,\n",
       "      'demand_lag1': 6912.7,\n",
       "      'demand_lag2': 7332.625,\n",
       "      'demand_lag3': 7576.558,\n",
       "      'demand_lag4': 7603.008,\n",
       "      'demand_lag5': 7788.292,\n",
       "      'demand_lag6': 8102.142,\n",
       "      'hour': 0,\n",
       "      'month': 6,\n",
       "      'precip': 0.0,\n",
       "      'temp': 74.63,\n",
       "      'temp_lag1': 75.1,\n",
       "      'temp_lag2': 75.72,\n",
       "      'temp_lag3': 76.72,\n",
       "      'temp_lag4': 75.85,\n",
       "      'temp_lag5': 77.36,\n",
       "      'temp_lag6': 80.92}],\n",
       "    'items': {'properties': {'dayofweek': {'format': 'int64',\n",
       "       'type': 'integer'},\n",
       "      'demand_lag1': {'format': 'double', 'type': 'number'},\n",
       "      'demand_lag2': {'format': 'double', 'type': 'number'},\n",
       "      'demand_lag3': {'format': 'double', 'type': 'number'},\n",
       "      'demand_lag4': {'format': 'double', 'type': 'number'},\n",
       "      'demand_lag5': {'format': 'double', 'type': 'number'},\n",
       "      'demand_lag6': {'format': 'double', 'type': 'number'},\n",
       "      'hour': {'format': 'int64', 'type': 'integer'},\n",
       "      'month': {'format': 'int64', 'type': 'integer'},\n",
       "      'precip': {'format': 'double', 'type': 'number'},\n",
       "      'temp': {'format': 'double', 'type': 'number'},\n",
       "      'temp_lag1': {'format': 'double', 'type': 'number'},\n",
       "      'temp_lag2': {'format': 'double', 'type': 'number'},\n",
       "      'temp_lag3': {'format': 'double', 'type': 'number'},\n",
       "      'temp_lag4': {'format': 'double', 'type': 'number'},\n",
       "      'temp_lag5': {'format': 'double', 'type': 'number'},\n",
       "      'temp_lag6': {'format': 'double', 'type': 'number'}},\n",
       "     'type': 'object'},\n",
       "    'type': 'array'},\n",
       "   'type': 3}}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_proj_dir = \"C:/Users/nelgoh/Desktop/Resources/Petronas/energy_demand_forecast/EnergyDemandForecast/\"\n",
    "inputs = {\"input_df\": SampleDefinition(DataTypes.PANDAS, test_df)}\n",
    "generate_schema(run_func=score.run, inputs=inputs, filepath=root_proj_dir + 'service_schema.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy the web service\n",
    "The command below deploys a web service names \"demandforecast\", with input schema defined by \"service_schema.json\". The web service runs \"score.py\" which scores the input data using the model \"model_deploy.pkl\". This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute set to modelstagingenv.\n"
     ]
    }
   ],
   "source": [
    "!az ml env set -n modelstagingenv -g pet_cg_azure_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model_deploy.pkl\n",
      "Successfully registered model\n",
      "Id: 2b7c1b6dd5b74996baf33bbdc034f4cb\n",
      "More information: 'az ml model show -m 2b7c1b6dd5b74996baf33bbdc034f4cb'\n",
      "Creating new driver at C:\\Users\\nelgoh\\AppData\\Local\\Temp\\4\\tmpnxvk4xmw.py\n",
      " score.py\n",
      " service_schema.json\n",
      "Successfully created manifest\n",
      "Id: 7d1b5cd3-1da2-4651-93b5-8e983a5b2a57\n",
      "More information: 'az ml manifest show -i 7d1b5cd3-1da2-4651-93b5-8e983a5b2a57'\n",
      "Creating image.....Done.\n",
      "Image ID: 0146874f-1622-492d-bd2a-b848b4a5bde3\n",
      "More details: 'az ml image show -i 0146874f-1622-492d-bd2a-b848b4a5bde3'\n",
      "Usage information: 'az ml image usage -i 0146874f-1622-492d-bd2a-b848b4a5bde3'\n",
      "[Local mode] Running docker container.\n",
      "[Local mode] Pulling the image from mlcrpacr1fb04691c711.azurecr.io/demandforecast:3. This may take a few minutes, depending on your connection speed...\n",
      "[Local mode] Pulling....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: {'Error': MlCliError({'Error': 'Unable to start container', 'Response Content': APIError(HTTPError('500 Server Error: Internal Server Error for url: http+docker://localnpipe/v1.35/containers/a8b6e1422050512352df878f7cf0f70a26efb9964b44e94f692e219da93641c7/start',),)},), 'Azure-cli-ml Version': None}\n"
     ]
    }
   ],
   "source": [
    "!az ml service create realtime -f score.py -m model_deploy.pkl -s service_schema.json -n demandforecast -r python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check web service is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: {\n",
      "    \"Azure-cli-ml Version\": null,\n",
      "    \"Error\": \"No service with id demandforecast is running locally.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!az ml service show realtime -i demandforecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the web service is working by invoking it with a test record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml service run realtime -i demandforecast -d \"{\\\"input_df\\\": [{\\\"hour\\\": 0, \\\"month\\\": 6, \\\"demand_lag3\\\": 7576.558, \\\"temp_lag5\\\": 77.36, \\\"temp\\\": 74.63, \\\"demand_lag1\\\": 6912.7, \\\"demand_lag5\\\": 7788.292, \\\"temp_lag6\\\": 80.92, \\\"temp_lag3\\\": 76.72, \\\"demand_lag6\\\": 8102.142, \\\"temp_lag4\\\": 75.85, \\\"precip\\\": 0.0, \\\"temp_lag2\\\": 75.72, \\\"demand_lag2\\\": 7332.625, \\\"temp_lag1\\\": 75.1, \\\"demand_lag4\\\": 7603.008, \\\"dayofweek\\\": 4}]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml service delete realtime --id=demandforecast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnergyDemandForecast local",
   "language": "python",
   "name": "energydemandforecast_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
