{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression with polynomial features of degree 2\n",
    "**Important**: Change the kernel to *PROJECT_NAME local*. You can do this from the *Kernel* menu under *Change kernel*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pickle\n",
    "import os\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.logging.script_run_request.ScriptRunRequest at 0x7f235eb92fd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.logging import get_azureml_logger\n",
    "run_logger = get_azureml_logger()\n",
    "run_logger.log('amlrealworld.timeseries.ridge-poly','true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ridge_poly2\"\n",
    "aml_dir = os.environ['AZUREML_NATIVE_SHARE_DIRECTORY']\n",
    "train = pd.read_csv(os.path.join(aml_dir, 'nyc_demand_train.csv'), parse_dates=['timeStamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model pipeline:\n",
    "- one-hot encode categorical features.\n",
    "- create polynomial features of degree 2. This means that for each pair of features $(x_1, x_2)$, the output features are $(x_1, x_2, x_1^2, x_1x_2, x_2^2)$\n",
    "- randomized parameter search with cross validation to find optimal values for the alpha parameter\n",
    "\n",
    "Note - to limit the training time, the number of iterations for the randomized search has been set to 20. This should train in about 3 minutes. increasing the number of iterations will increase the likelihood of finding the optimum solution but also increase training times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['demand', 'timeStamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['hour', 'month', 'dayofweek']\n",
    "cat_cols_idx = [X.columns.get_loc(c) for c in X.columns if c in cat_cols]\n",
    "onehot = OneHotEncoder(categorical_features=cat_cols_idx, sparse=False)\n",
    "regr = Ridge(fit_intercept=False)\n",
    "poly = PolynomialFeatures(2)\n",
    "tscv = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] alpha=4.90403025516 .............................................\n",
      "[CV] .............................. alpha=4.90403025516, total=   0.8s\n",
      "[CV] alpha=4.90403025516 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. alpha=4.90403025516, total=   1.4s\n",
      "[CV] alpha=4.90403025516 .............................................\n",
      "[CV] .............................. alpha=4.90403025516, total=   2.1s\n",
      "[CV] alpha=1.41255238507 .............................................\n",
      "[CV] .............................. alpha=1.41255238507, total=   0.8s\n",
      "[CV] alpha=1.41255238507 .............................................\n",
      "[CV] .............................. alpha=1.41255238507, total=   1.4s\n",
      "[CV] alpha=1.41255238507 .............................................\n",
      "[CV] .............................. alpha=1.41255238507, total=   2.1s\n",
      "[CV] alpha=3.76275618078 .............................................\n",
      "[CV] .............................. alpha=3.76275618078, total=   0.8s\n",
      "[CV] alpha=3.76275618078 .............................................\n",
      "[CV] .............................. alpha=3.76275618078, total=   1.4s\n",
      "[CV] alpha=3.76275618078 .............................................\n",
      "[CV] .............................. alpha=3.76275618078, total=   2.1s\n",
      "[CV] alpha=2.54403191676 .............................................\n",
      "[CV] .............................. alpha=2.54403191676, total=   0.8s\n",
      "[CV] alpha=2.54403191676 .............................................\n",
      "[CV] .............................. alpha=2.54403191676, total=   1.6s\n",
      "[CV] alpha=2.54403191676 .............................................\n",
      "[CV] .............................. alpha=2.54403191676, total=   2.1s\n",
      "[CV] alpha=0.803024610676 ............................................\n",
      "[CV] ............................. alpha=0.803024610676, total=   0.8s\n",
      "[CV] alpha=0.803024610676 ............................................\n",
      "[CV] ............................. alpha=0.803024610676, total=   1.5s\n",
      "[CV] alpha=0.803024610676 ............................................\n",
      "[CV] ............................. alpha=0.803024610676, total=   2.1s\n",
      "[CV] alpha=4.48631240028 .............................................\n",
      "[CV] .............................. alpha=4.48631240028, total=   1.1s\n",
      "[CV] alpha=4.48631240028 .............................................\n",
      "[CV] .............................. alpha=4.48631240028, total=   1.5s\n",
      "[CV] alpha=4.48631240028 .............................................\n",
      "[CV] .............................. alpha=4.48631240028, total=   2.3s\n",
      "[CV] alpha=3.91877045444 .............................................\n",
      "[CV] .............................. alpha=3.91877045444, total=   1.1s\n",
      "[CV] alpha=3.91877045444 .............................................\n",
      "[CV] .............................. alpha=3.91877045444, total=   1.4s\n",
      "[CV] alpha=3.91877045444 .............................................\n",
      "[CV] .............................. alpha=3.91877045444, total=   2.1s\n",
      "[CV] alpha=4.34519354491 .............................................\n",
      "[CV] .............................. alpha=4.34519354491, total=   0.8s\n",
      "[CV] alpha=4.34519354491 .............................................\n",
      "[CV] .............................. alpha=4.34519354491, total=   1.4s\n",
      "[CV] alpha=4.34519354491 .............................................\n",
      "[CV] .............................. alpha=4.34519354491, total=   2.0s\n",
      "[CV] alpha=2.67828503847 .............................................\n",
      "[CV] .............................. alpha=2.67828503847, total=   0.8s\n",
      "[CV] alpha=2.67828503847 .............................................\n",
      "[CV] .............................. alpha=2.67828503847, total=   1.6s\n",
      "[CV] alpha=2.67828503847 .............................................\n",
      "[CV] .............................. alpha=2.67828503847, total=   2.1s\n",
      "[CV] alpha=1.23704128253 .............................................\n",
      "[CV] .............................. alpha=1.23704128253, total=   0.8s\n",
      "[CV] alpha=1.23704128253 .............................................\n",
      "[CV] .............................. alpha=1.23704128253, total=   1.4s\n",
      "[CV] alpha=1.23704128253 .............................................\n",
      "[CV] .............................. alpha=1.23704128253, total=   2.1s\n",
      "[CV] alpha=4.59836060798 .............................................\n",
      "[CV] .............................. alpha=4.59836060798, total=   0.8s\n",
      "[CV] alpha=4.59836060798 .............................................\n",
      "[CV] .............................. alpha=4.59836060798, total=   1.5s\n",
      "[CV] alpha=4.59836060798 .............................................\n",
      "[CV] .............................. alpha=4.59836060798, total=   2.1s\n",
      "[CV] alpha=0.879542881096 ............................................\n",
      "[CV] ............................. alpha=0.879542881096, total=   0.8s\n",
      "[CV] alpha=0.879542881096 ............................................\n",
      "[CV] ............................. alpha=0.879542881096, total=   1.7s\n",
      "[CV] alpha=0.879542881096 ............................................\n",
      "[CV] ............................. alpha=0.879542881096, total=   2.5s\n",
      "[CV] alpha=4.56622688794 .............................................\n",
      "[CV] .............................. alpha=4.56622688794, total=   0.8s\n",
      "[CV] alpha=4.56622688794 .............................................\n",
      "[CV] .............................. alpha=4.56622688794, total=   1.5s\n",
      "[CV] alpha=4.56622688794 .............................................\n",
      "[CV] .............................. alpha=4.56622688794, total=   2.5s\n",
      "[CV] alpha=2.47959512911 .............................................\n",
      "[CV] .............................. alpha=2.47959512911, total=   0.9s\n",
      "[CV] alpha=2.47959512911 .............................................\n",
      "[CV] .............................. alpha=2.47959512911, total=   1.4s\n",
      "[CV] alpha=2.47959512911 .............................................\n",
      "[CV] .............................. alpha=2.47959512911, total=   2.1s\n",
      "[CV] alpha=1.71584870664 .............................................\n",
      "[CV] .............................. alpha=1.71584870664, total=   1.0s\n",
      "[CV] alpha=1.71584870664 .............................................\n",
      "[CV] .............................. alpha=1.71584870664, total=   1.8s\n",
      "[CV] alpha=1.71584870664 .............................................\n",
      "[CV] .............................. alpha=1.71584870664, total=   2.4s\n",
      "[CV] alpha=3.68312884238 .............................................\n",
      "[CV] .............................. alpha=3.68312884238, total=   0.9s\n",
      "[CV] alpha=3.68312884238 .............................................\n",
      "[CV] .............................. alpha=3.68312884238, total=   1.5s\n",
      "[CV] alpha=3.68312884238 .............................................\n",
      "[CV] .............................. alpha=3.68312884238, total=   2.1s\n",
      "[CV] alpha=2.4194273395 ..............................................\n",
      "[CV] ............................... alpha=2.4194273395, total=   0.9s\n",
      "[CV] alpha=2.4194273395 ..............................................\n",
      "[CV] ............................... alpha=2.4194273395, total=   1.5s\n",
      "[CV] alpha=2.4194273395 ..............................................\n",
      "[CV] ............................... alpha=2.4194273395, total=   2.5s\n",
      "[CV] alpha=1.92343241217 .............................................\n",
      "[CV] .............................. alpha=1.92343241217, total=   1.1s\n",
      "[CV] alpha=1.92343241217 .............................................\n",
      "[CV] .............................. alpha=1.92343241217, total=   2.0s\n",
      "[CV] alpha=1.92343241217 .............................................\n",
      "[CV] .............................. alpha=1.92343241217, total=   2.2s\n",
      "[CV] alpha=0.0392462510614 ...........................................\n",
      "[CV] ............................ alpha=0.0392462510614, total=   0.9s\n",
      "[CV] alpha=0.0392462510614 ...........................................\n",
      "[CV] ............................ alpha=0.0392462510614, total=   1.5s\n",
      "[CV] alpha=0.0392462510614 ...........................................\n",
      "[CV] ............................ alpha=0.0392462510614, total=   2.2s\n",
      "[CV] alpha=1.74900498531 .............................................\n",
      "[CV] .............................. alpha=1.74900498531, total=   0.8s\n",
      "[CV] alpha=1.74900498531 .............................................\n",
      "[CV] .............................. alpha=1.74900498531, total=   1.9s\n",
      "[CV] alpha=1.74900498531 .............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. alpha=1.74900498531, total=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('onehot', OneHotEncoder(categorical_features=[2, 3, 4], dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=False)), ('poly', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('regr_cv', RandomizedSearchCV(cv=TimeSeriesSplit(max_trai...=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=2))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = {'alpha': st.uniform(1e-4, 5.0)}\n",
    "regr_cv = RandomizedSearchCV(estimator=regr,\n",
    "                            param_distributions=param_dist,\n",
    "                            n_iter=20,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            iid=False,\n",
    "                            cv=tscv,\n",
    "                            verbose=2,\n",
    "                            n_jobs=1)\n",
    "regr_pipe = Pipeline([('onehot', onehot), ('poly', poly), ('regr_cv', regr_cv)])\n",
    "regr_pipe.fit(X, y=train['demand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(aml_dir, model_name + '.pkl'), 'wb') as f:\n",
    "    pickle.dump(regr_pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.661420</td>\n",
       "      <td>0.015016</td>\n",
       "      <td>-1247.836161</td>\n",
       "      <td>-1044.319558</td>\n",
       "      <td>0.879543</td>\n",
       "      <td>{'alpha': 0.879542881096}</td>\n",
       "      <td>1</td>\n",
       "      <td>-1373.651814</td>\n",
       "      <td>-1012.003444</td>\n",
       "      <td>-1078.397714</td>\n",
       "      <td>-1076.942261</td>\n",
       "      <td>-1291.458956</td>\n",
       "      <td>-1044.012970</td>\n",
       "      <td>0.700400</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>124.421212</td>\n",
       "      <td>26.512047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.443228</td>\n",
       "      <td>0.018448</td>\n",
       "      <td>-1247.912906</td>\n",
       "      <td>-1043.642910</td>\n",
       "      <td>0.803025</td>\n",
       "      <td>{'alpha': 0.803024610676}</td>\n",
       "      <td>2</td>\n",
       "      <td>-1373.757923</td>\n",
       "      <td>-1010.842679</td>\n",
       "      <td>-1078.372787</td>\n",
       "      <td>-1076.423058</td>\n",
       "      <td>-1291.608008</td>\n",
       "      <td>-1043.662993</td>\n",
       "      <td>0.530786</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>124.485718</td>\n",
       "      <td>26.773081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.435197</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>-1247.945671</td>\n",
       "      <td>-1047.321469</td>\n",
       "      <td>1.23704</td>\n",
       "      <td>{'alpha': 1.23704128253}</td>\n",
       "      <td>3</td>\n",
       "      <td>-1374.232920</td>\n",
       "      <td>-1017.238619</td>\n",
       "      <td>-1078.592770</td>\n",
       "      <td>-1079.185839</td>\n",
       "      <td>-1291.011324</td>\n",
       "      <td>-1045.539949</td>\n",
       "      <td>0.508223</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>124.476938</td>\n",
       "      <td>25.321202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.432041</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>-1248.221380</td>\n",
       "      <td>-1048.733526</td>\n",
       "      <td>1.41255</td>\n",
       "      <td>{'alpha': 1.41255238507}</td>\n",
       "      <td>4</td>\n",
       "      <td>-1375.032865</td>\n",
       "      <td>-1019.740081</td>\n",
       "      <td>-1078.727171</td>\n",
       "      <td>-1080.218669</td>\n",
       "      <td>-1290.904102</td>\n",
       "      <td>-1046.241826</td>\n",
       "      <td>0.550469</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>124.674582</td>\n",
       "      <td>24.753065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.710671</td>\n",
       "      <td>0.021883</td>\n",
       "      <td>-1248.956071</td>\n",
       "      <td>-1051.119795</td>\n",
       "      <td>1.71585</td>\n",
       "      <td>{'alpha': 1.71584870664}</td>\n",
       "      <td>5</td>\n",
       "      <td>-1377.008919</td>\n",
       "      <td>-1024.004186</td>\n",
       "      <td>-1079.015052</td>\n",
       "      <td>-1081.948600</td>\n",
       "      <td>-1290.844242</td>\n",
       "      <td>-1047.406598</td>\n",
       "      <td>0.588769</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>125.209292</td>\n",
       "      <td>23.800975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "11       1.661420         0.015016     -1247.836161      -1044.319558   \n",
       "4        1.443228         0.018448     -1247.912906      -1043.642910   \n",
       "9        1.435197         0.014523     -1247.945671      -1047.321469   \n",
       "1        1.432041         0.014388     -1248.221380      -1048.733526   \n",
       "14       1.710671         0.021883     -1248.956071      -1051.119795   \n",
       "\n",
       "   param_alpha                     params  rank_test_score  split0_test_score  \\\n",
       "11    0.879543  {'alpha': 0.879542881096}                1       -1373.651814   \n",
       "4     0.803025  {'alpha': 0.803024610676}                2       -1373.757923   \n",
       "9      1.23704   {'alpha': 1.23704128253}                3       -1374.232920   \n",
       "1      1.41255   {'alpha': 1.41255238507}                4       -1375.032865   \n",
       "14     1.71585   {'alpha': 1.71584870664}                5       -1377.008919   \n",
       "\n",
       "    split0_train_score  split1_test_score  split1_train_score  \\\n",
       "11        -1012.003444       -1078.397714        -1076.942261   \n",
       "4         -1010.842679       -1078.372787        -1076.423058   \n",
       "9         -1017.238619       -1078.592770        -1079.185839   \n",
       "1         -1019.740081       -1078.727171        -1080.218669   \n",
       "14        -1024.004186       -1079.015052        -1081.948600   \n",
       "\n",
       "    split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "11       -1291.458956        -1044.012970      0.700400        0.000166   \n",
       "4        -1291.608008        -1043.662993      0.530786        0.002507   \n",
       "9        -1291.011324        -1045.539949      0.508223        0.000093   \n",
       "1        -1290.904102        -1046.241826      0.550469        0.000229   \n",
       "14       -1290.844242        -1047.406598      0.588769        0.007859   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "11      124.421212        26.512047  \n",
       "4       124.485718        26.773081  \n",
       "9       124.476938        25.321202  \n",
       "1       124.674582        24.753065  \n",
       "14      125.209292        23.800975  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(regr_pipe.named_steps['regr_cv'].cv_results_)\n",
    "cv_results.sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEICAYAAACavRnhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAA5UXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f235ea999b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cv_results['param_alpha'], cv_results['mean_test_score'], 'ro', markersize=1)\n",
    "plt.title('CV negative mean squared error')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TimeSeriesForecastingTutorial local",
   "language": "python",
   "name": "timeseriesforecastingtutorial_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
